{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available:  True\n",
      "CUDA device count:  1\n",
      "CUDA device name:  NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Is CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA device count: \", torch.cuda.device_count())\n",
    "print(\"CUDA device name: \", torch.cuda.get_device_name(0))\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import background\n",
    "import os\n",
    "\n",
    "def combine_excel_files(folder_path):\n",
    "    dataframes = []\n",
    "    first_df_columns = None\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_excel(file_path)\n",
    "            df = background.structured_data(df)\n",
    "            first_df_columns = df.columns.tolist()\n",
    "            break\n",
    "    \n",
    "    if not first_df_columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            df = pd.read_excel(file_path)\n",
    "            df = background.structured_data(df)\n",
    "            \n",
    "            city_name = os.path.splitext(filename)[0]\n",
    "            df['city'] = city_name\n",
    "            \n",
    "            for col in first_df_columns + ['city']:\n",
    "                if col not in df.columns:\n",
    "                    raise ValueError(f\"Column {col} missing in file {filename}\")\n",
    "            \n",
    "            df = df[first_df_columns + ['city']]\n",
    "            \n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            dataframes.append(df)\n",
    "    \n",
    "    if dataframes:\n",
    "        all_data = pd.concat(dataframes, ignore_index=True)\n",
    "        return all_data\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "folder_path = 'dataset'\n",
    "result = combine_excel_files(folder_path)\n",
    "duplicate_columns = result.columns[result.columns.duplicated()].tolist()\n",
    "\n",
    "if duplicate_columns:\n",
    "    result = result.loc[:, ~result.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_info = {}\n",
    "\n",
    "for col in result.columns:\n",
    "    unique_info[col] = {\n",
    "        'unique_count': result[col].nunique(),\n",
    "        'unique_values': result[col].unique().tolist()\n",
    "    }\n",
    "print(\"columns droped are\")\n",
    "for col, info in unique_info.items():\n",
    "    if info['unique_count'] == 1:    \n",
    "        print(f\"Column: {col}\")\n",
    "        result.drop([col],axis=1,inplace=True)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df, threshold_percentage=0.1):\n",
    "    columns_to_drop = set()\n",
    "        \n",
    "    nan_counts = df.isnull().mean() \n",
    "    \n",
    "    columns_to_drop.update(nan_counts[nan_counts > threshold_percentage].index)\n",
    "    \n",
    "    empty_str_count = (df == '').mean() \n",
    "    \n",
    "    columns_to_drop.update(empty_str_count[empty_str_count > threshold_percentage].index)\n",
    "    \n",
    "    space_only_count = (df.applymap(lambda x: isinstance(x, str) and x.isspace())).mean()\n",
    "    \n",
    "    columns_to_drop.update(space_only_count[space_only_count > threshold_percentage].index)\n",
    "    \n",
    "    problematic_values = ['N/A', 'NA', 'null', 'NULL']\n",
    "    for value in problematic_values:\n",
    "        problematic_count = (df == value).mean()\n",
    "        \n",
    "        columns_to_drop.update(problematic_count[problematic_count > threshold_percentage].index)\n",
    "    \n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "    print(\"\\nColumns dropped:\", columns_to_drop)\n",
    "    return df\n",
    "result = check_missing_values(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(['oem','misc_Seating Capacity','ft','kms_driven','year_of_manufacture','ownership','owner','engine','engine_displacement','registration_year','engine_Max Power','engine_Max Torque'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_price(price):\n",
    "    price = price.replace('₹', '').replace(',', '').strip()\n",
    "    \n",
    "    if 'Lakh' in price:\n",
    "        value = float(price.replace('Lakh', '').strip())\n",
    "        return value * 100000 \n",
    "    elif 'Crore' in price:\n",
    "        value = float(price.replace('Crore', '').strip())\n",
    "        return value * 10000000 \n",
    "    else:\n",
    "        return float(price)\n",
    "\n",
    "df = result['price'].apply(convert_price)\n",
    "result.drop('price',axis=1,inplace=True)\n",
    "result=pd.concat([result,df],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna()\n",
    "result['seats'] = result['seats'].str.extract('(\\d+)').astype(int)\n",
    "result['mileage'] = result['mileage'].str.replace(',', '').str.extract('(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "result['max_power'] = result['max_power'].str.replace(',', '').str.extract('(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "result['torque'] = result['torque'].str.replace(',', '').str.extract('(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "result['dimension_Length'] = result['dimension_Length'].str.extract('(\\d+)').astype(int)\n",
    "result['dimension_Width'] = result['dimension_Width'].str.extract('(\\d+)').astype(int)\n",
    "result['dimension_Height'] = result['dimension_Height'].str.extract('(\\d+)').astype(int)\n",
    "result['dimension_Wheel Base'] = result['dimension_Wheel Base'].str.extract('(\\d+)').astype(int)\n",
    "result['dimension_Kerb Weight'] = result['dimension_Kerb Weight'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['km'] = result['km'].str.replace(',', '').str.strip().astype(int)\n",
    "result['engine_Displacement'] = result['engine_Displacement'].astype(int) \n",
    "result['misc_No Door Numbers'] = result['misc_No Door Numbers'].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('fulldata.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('fulldata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[['transmission','modelYear','misc_Gear Box','city','insurance_validity','ownerNo','km','bt','mileage','fuel_type','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features=['Transmission','Model_Year','Gear_Box','city','Insurance_Validity','No_Of_Owners','km_driven','Body_Type','Mileage','Fuel_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = top_features\n",
    "\n",
    "with open('car_dheko_app/model/my_list.txt', 'w') as f:\n",
    "    for item in my_list:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "target_column = 'price'\n",
    "\n",
    "columns_to_plot = [col for col in df1.columns if col != target_column]\n",
    "\n",
    "plt.figure(figsize=(15, len(columns_to_plot) * 4))\n",
    "\n",
    "for i, col in enumerate(columns_to_plot, 1):\n",
    "    plt.subplot(len(columns_to_plot), 1, i)\n",
    "    sns.boxplot(data=df1, y=col)\n",
    "    plt.title(f\"Box Plot of {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[df1['mileage']<df1['mileage'].max()-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[df1['km']<df1['km'].max()-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df1['modelYear'].quantile(0.25)\n",
    "Q3 = df1['modelYear'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df1 = df1[(df1['modelYear'] >= lower_bound) & (df1['modelYear'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=df1['transmission'].unique()\n",
    "with open('car_dheko_app/model/transmission.txt', 'w') as f:\n",
    "    for item in list1:\n",
    "        f.write(f\"{item}\\n\")\n",
    "list1=df1['misc_Gear Box'].unique()\n",
    "with open('car_dheko_app/model/Gear_Box.txt', 'w') as f:\n",
    "    for item in list1:\n",
    "        f.write(f\"{item}\\n\")\n",
    "list1=df1['city'].unique()\n",
    "with open('car_dheko_app/model/city.txt', 'w') as f:\n",
    "    for item in list1:\n",
    "        f.write(f\"{item}\\n\")\n",
    "list1=df1['bt'].unique()\n",
    "with open('car_dheko_app/model/bodytype.txt', 'w') as f:\n",
    "    for item in list1:\n",
    "        f.write(f\"{item}\\n\")\n",
    "list1=df1['insurance_validity'].unique()\n",
    "with open('car_dheko_app/model/insurance.txt', 'w') as f:\n",
    "    for item in list1:\n",
    "        f.write(f\"{item}\\n\")\n",
    "list1=df1['fuel_type'].unique()\n",
    "with open('car_dheko_app/model/fuel.txt', 'w') as f:\n",
    "    for item in list1:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df1.select_dtypes(include=['number'])\n",
    "categorical = df1.select_dtypes(exclude=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "label_encoders = {}\n",
    "df2 = categorical\n",
    "\n",
    "for column in df2.columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df2[column] = label_encoder.fit_transform(categorical[column])\n",
    "    \n",
    "    label_encoders[column] = label_encoder\n",
    "\n",
    "joblib.dump(label_encoders, 'car_dheko_app/model/label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df=pd.concat([df2,numerical],axis=1)\n",
    "df=df[['transmission','modelYear','misc_Gear Box','city','insurance_validity','ownerNo','km','bt','mileage','fuel_type','price']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price']=df['price']/100000\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import * \n",
    "\n",
    "target_column = 'price'\n",
    "\n",
    "reg_setup = setup(data=df, target=target_column, preprocess=False, verbose=False)\n",
    "\n",
    "best_model = compare_models()\n",
    "\n",
    "print(\"Best model based on RMSE:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(best_model, plot='residuals') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and print the best model's parameters directly\n",
    "best_model_params = best_model.get_params()\n",
    "print(\"Parameters used for the best model:\")\n",
    "print(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=df['price']\n",
    "df.drop('price',axis=1,inplace=True)\n",
    "X=df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100,150,200],         \n",
    "    'max_depth': [None, 10, 20,30],       \n",
    "    'min_samples_split': [2,5,6,7],   \n",
    "    'min_samples_leaf': [1, 2, 4],           \n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]           \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=best_model, param_grid=param_grid, n_jobs=-1, verbose=0, scoring='r2')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best R² Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2_score_final = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('car_dheko_app/model/model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
